{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNET.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YjY93NhhkvXJ"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def double_conv(in_c , out_c):\n",
        "  conv = nn.Sequential(\n",
        "      nn.Conv2d(in_c , out_c , kernel_size=3),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(out_c, out_c , kernel_size=3),\n",
        "      nn.ReLU(inplace=True),\n",
        "  )\n",
        "  return conv"
      ],
      "metadata": {
        "id": "oU3qvBPblDGl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_img(tensor , target_tensor):\n",
        "  target_size = target_tensor.size()[2]\n",
        "  tensor_size = tensor.size()[2]\n",
        "  #cropping \n",
        "  delta = tensor_size-target_size\n",
        "  delta = delta//2\n",
        "  return tensor[:,:,delta:tensor_size-delta , delta:tensor_size-delta ]\n"
      ],
      "metadata": {
        "id": "yOSy0hj0vfGy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(UNet , self).__init__()\n",
        "\n",
        "    self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2 , stride = 2)\n",
        "\n",
        "    #down convolution , left half of the U (Contracting path)\n",
        "    self.down_conv1 = double_conv(1,64)\n",
        "    self.down_conv2 = double_conv(64,128)\n",
        "    self.down_conv3 = double_conv(128,256)\n",
        "    self.down_conv4 = double_conv(256,512)\n",
        "    self.down_conv5 = double_conv(512,1024)\n",
        "\n",
        "    #up convolution , right half of the U (Expansive path)\n",
        "    self.up_trans_1 = nn.ConvTranspose2d(\n",
        "        in_channels = 1024,\n",
        "        out_channels = 512,\n",
        "        kernel_size=2,\n",
        "        stride=2)\n",
        "    self.up_conv1 = double_conv(1024,512)\n",
        "\n",
        "    \n",
        "    self.up_trans_2 = nn.ConvTranspose2d(\n",
        "        in_channels = 512,\n",
        "        out_channels = 256,\n",
        "        kernel_size=2,\n",
        "        stride=2)\n",
        "    self.up_conv2 = double_conv(512,256)\n",
        "\n",
        "\n",
        "    self.up_trans_3 = nn.ConvTranspose2d(\n",
        "        in_channels = 256,\n",
        "        out_channels = 128,\n",
        "        kernel_size=2,\n",
        "        stride=2)\n",
        "    self.up_conv3 = double_conv(256,128)\n",
        "\n",
        "\n",
        "    self.up_trans_4 = nn.ConvTranspose2d(\n",
        "        in_channels = 128,\n",
        "        out_channels = 64,\n",
        "        kernel_size=2,\n",
        "        stride=2)\n",
        "    self.up_conv4 = double_conv(128,64)\n",
        "\n",
        "    self.out = nn.Conv2d(\n",
        "        in_channels = 64,\n",
        "        out_channels = 2,\n",
        "        kernel_size = 1\n",
        "    )\n",
        "\n",
        "  def forward(self , image):\n",
        "    #encoder \n",
        "    x1 = self.down_conv1(image)\n",
        "    x2 = self.max_pool_2x2(x1)\n",
        "    x3 = self.down_conv2(x2)\n",
        "    x4 = self.max_pool_2x2(x3)\n",
        "    x5 = self.down_conv3(x4)\n",
        "    x6 = self.max_pool_2x2(x5)\n",
        "    x7 = self.down_conv4(x6)\n",
        "    x8 = self.max_pool_2x2(x7)\n",
        "    x9 = self.down_conv5(x8)\n",
        "\n",
        "    #decoder\n",
        "    x = self.up_trans_1(x9)\n",
        "    y = crop_img(x7,x)\n",
        "    x = self.up_conv1(torch.cat([x,y],1))\n",
        "\n",
        "    x = self.up_trans_2(x)\n",
        "    y = crop_img(x5,x)\n",
        "    x = self.up_conv2(torch.cat([x,y],1))\n",
        "\n",
        "    x = self.up_trans_3(x)\n",
        "    y = crop_img(x3,x)\n",
        "    x = self.up_conv3(torch.cat([x,y],1))\n",
        "\n",
        "    x = self.up_trans_4(x)\n",
        "    y = crop_img(x1,x)\n",
        "    x = self.up_conv4(torch.cat([x,y],1))\n",
        "\n",
        "    x = self.out(x)\n",
        "    print(x.size())\n",
        "    return x"
      ],
      "metadata": {
        "id": "VFbTERkGlqrY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  image = torch.rand((1,1,572,572)) #(batch size , chanels , height , width)\n",
        "  model = UNet()\n",
        "  print(model(image))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFFJPge5nlVl",
        "outputId": "cf5e2edd-ce8c-43d8-bd6b-7b1652247462"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2, 388, 388])\n",
            "tensor([[[[0.1205, 0.1267, 0.1166,  ..., 0.1255, 0.1269, 0.1298],\n",
            "          [0.1237, 0.1200, 0.1170,  ..., 0.1249, 0.1235, 0.1252],\n",
            "          [0.1220, 0.1248, 0.1247,  ..., 0.1263, 0.1268, 0.1224],\n",
            "          ...,\n",
            "          [0.1268, 0.1227, 0.1234,  ..., 0.1274, 0.1180, 0.1239],\n",
            "          [0.1209, 0.1234, 0.1272,  ..., 0.1204, 0.1250, 0.1246],\n",
            "          [0.1206, 0.1210, 0.1236,  ..., 0.1249, 0.1220, 0.1282]],\n",
            "\n",
            "         [[0.0172, 0.0188, 0.0176,  ..., 0.0208, 0.0199, 0.0238],\n",
            "          [0.0193, 0.0205, 0.0136,  ..., 0.0231, 0.0202, 0.0238],\n",
            "          [0.0193, 0.0162, 0.0154,  ..., 0.0194, 0.0189, 0.0254],\n",
            "          ...,\n",
            "          [0.0173, 0.0219, 0.0187,  ..., 0.0171, 0.0159, 0.0192],\n",
            "          [0.0272, 0.0209, 0.0133,  ..., 0.0191, 0.0212, 0.0252],\n",
            "          [0.0212, 0.0163, 0.0221,  ..., 0.0216, 0.0219, 0.0215]]]],\n",
            "       grad_fn=<ThnnConv2DBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DWWpCCHBoOUQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}